{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "# Observer Problem\n",
    "How can we watch for state changes and events in a manner that allows\n",
    "us to extend and test our code without making a codebase woven with\n",
    "orthogonal concerns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class NeuralNetwork():\n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        Returns our prediction (output)\n",
    "        \"\"\"\n",
    "        print('Forward Pass')\n",
    "    \n",
    "    def backward(self, loss):\n",
    "        \"\"\"\n",
    "        Backward pass through the network\n",
    "        Returns our gradients given the loss\n",
    "        \"\"\"\n",
    "        print('Backward Pass')\n",
    "        \n",
    "    \n",
    "    def computeLoss(self, preds):\n",
    "        \"\"\"\n",
    "        Compute our loss between pred / actual\n",
    "        \"\"\"\n",
    "        print('Compute Loss')\n",
    "    \n",
    "    def updateWeights(self, gradients, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Given the gradients and our learning rate, update our weights\n",
    "        \"\"\"\n",
    "        print('Update Weight Parameters')\n",
    "    \n",
    "    def train(self, epochs, batches):\n",
    "        \"\"\"\n",
    "        Training loop, for each epoch, for each batch\n",
    "\n",
    "        \"\"\"\n",
    "        for epoch in epochs:\n",
    "            for batch in batches():\n",
    "                preds = self.forward(batch)\n",
    "                loss  = self.computeLoss(preds)\n",
    "                gradients = self.backward(loss)\n",
    "                self.updateWeights(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2,
    "region_name": "md"
   },
   "source": [
    "# Extend Functionality\n",
    "In this example, we want to do three things:\n",
    "* Adjust learning rate schedule (annealling)                \n",
    "* Log loss after each batch\n",
    "* Log accuracy after each epoch\n",
    "We're also quite sure we'll want to make more adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "# Observer Pattern\n",
    "* Rather than add orthoginal code into our net, we separate concerns\n",
    "* Observed -> Code that creates events / state changes (our neural network)\n",
    "* Observer -> Watches for changes and dispatches events to those who are interested\n",
    "* Callback -> The interface an iterested party implements to get notified \n",
    "Note:  Our code focuses on a specific implementation, and takes advantage of dunders\n",
    "for implementation details. We don't fully implement a neural net as well\n",
    "preferring to focus on the details of the three actors in this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    \"\"\"\n",
    "    Marker Interface\n",
    "    \"\"\"\n",
    "    pass  \n",
    "    \n",
    "class Observer():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Create a list of callbacks\n",
    "        \"\"\"\n",
    "        self.callbacks = []\n",
    "        \n",
    "    def registerCallback(self, callback):\n",
    "        \"\"\"\n",
    "        Add the callback to our list\n",
    "        \"\"\"\n",
    "        self.callbacks.append(callback)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Got an event, invoke on our callbacks given the name\n",
    "        \"\"\"\n",
    "        invoke = args[0]\n",
    "        for c in self.callbacks:\n",
    "            try:\n",
    "                func = getattr(c, invoke)\n",
    "                func(args[1])\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "# Network 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, callbacks=None):\n",
    "        \"\"\"\n",
    "        Setup an observer and add the callbacks provided\n",
    "        \"\"\"\n",
    "        self.observer = Observer()\n",
    "        if callbacks is not None:\n",
    "            for c in callbacks:\n",
    "                self.observer.registerCallback(c) \n",
    "                \n",
    "    def observe(self, action, state={}):\n",
    "        \"\"\"\n",
    "        Observed a state or event, propagate to observer to forward\n",
    "        Set a reference to this neural network\n",
    "        \"\"\"\n",
    "        state['net'] = self\n",
    "        self.observer(action, state)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        Returns our prediction (output)\n",
    "        \"\"\"\n",
    "        print('Forward Pass')\n",
    "    \n",
    "    def backward(self, loss):\n",
    "        \"\"\"\n",
    "        Backward pass through the network\n",
    "        Returns our gradients given the loss\n",
    "        \"\"\"\n",
    "        print('Backward Pass')\n",
    "          \n",
    "    def computeLoss(self, preds):\n",
    "        \"\"\"\n",
    "        Compute our loss between pred / actual\n",
    "        \"\"\"\n",
    "        print('Compute Loss')\n",
    "        return np.random.random()\n",
    "        \n",
    "    def computeAccuracy(self):\n",
    "        \"\"\"\n",
    "        Compute our loss between pred / actual\n",
    "        \"\"\"\n",
    "        print('Compute Accuracy')\n",
    "        return np.random.random()\n",
    "    \n",
    "    def updateWeights(self, gradients, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Given the gradients and our learning rate, update our weights\n",
    "        \"\"\"\n",
    "        print('Update Weight Parameters')\n",
    "    \n",
    "    def train(self, epochs, batches, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Training loop, for each epoch, for each batch\n",
    "\n",
    "        \"\"\"\n",
    "        state = {}\n",
    "        state['epochs']  = epochs\n",
    "        state['batches'] = batches\n",
    "        state['learning_rate'] = learning_rate\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            state['epoch'] = epoch\n",
    "            self.observe('beforeEpoch', state)\n",
    "            \n",
    "            for batch in range(batches):\n",
    "                state['batch'] = batch\n",
    "                self.observe('beforeBatch', state)\n",
    "                \n",
    "                preds = self.forward(batch)\n",
    "                loss  = self.computeLoss(preds)\n",
    "                gradients = self.backward(loss)\n",
    "                self.updateWeights(gradients)\n",
    "                \n",
    "                state['loss'] = loss\n",
    "                self.observe('afterBatch', state)\n",
    "                \n",
    "            accuracy = self.computeAccuracy()\n",
    "            state['accuracy'] = accuracy                \n",
    "            self.observe('afterEpoch', state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "class CallbackLogging(Callback):\n",
    "    def beforeEpoch(self, state):\n",
    "        print(f'-> Before Epoch {state[\"epoch\"] + 1} of {state[\"epochs\"]}')\n",
    "    \n",
    "    def afterEpoch(self, state):\n",
    "        print(f'-> After Epoch {state[\"epoch\"] + 1} of {state[\"epochs\"]}\\n')\n",
    "    \n",
    "    def beforeBatch(self, state):\n",
    "        print(f'--> Before Batch {state[\"batch\"] + 1} of {state[\"batches\"]}')\n",
    "    \n",
    "    def afterBatch(self, state):\n",
    "        print(f'--> After Batch {state[\"batch\"] + 1} of {state[\"batches\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "logger   = CallbackLogging()\n",
    "ann = NeuralNetwork(callbacks=[logger])\n",
    "ann.train(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "# Callback Loss & Accuracy Tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "class CallbackMetricTracker(Callback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.accuracy = []\n",
    "        \n",
    "    def afterBatch(self, state):\n",
    "        self.losses.append(state['loss'])\n",
    "        \n",
    "    def afterEpoch(self, state):\n",
    "        self.accuracy.append(state['accuracy'])\n",
    "        \n",
    "    def __str__(self):\n",
    "        return(f'Losses {self.losses}\\nAccuracy {self.accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "logger   = CallbackLogging()\n",
    "tracker  = CallbackMetricTracker()\n",
    "ann = NeuralNetwork(callbacks=[logger, tracker])\n",
    "ann.train(2,2)     \n",
    "print(tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "region_name": "md"
   },
   "source": [
    "# Callback Learning Rate Annealing\n",
    "Most modern frameworks (PyTorch, Keras, TF), hold the learning rate with the optimizer.\n",
    "In this simple net, we're building our network and optimizer in one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "class CallbackLearningRate(Callback):    \n",
    "    def afterBatch(self, state):\n",
    "        \"\"\"\n",
    "        Log a message for demo\n",
    "        \"\"\"\n",
    "        print(f'. Anneal learning rate {state[\"learning_rate\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "codecell"
   },
   "outputs": [],
   "source": [
    "logger   = CallbackLogging()\n",
    "tracker  = CallbackMetricTracker()\n",
    "learning = CallbackLearningRate()\n",
    "ann = NeuralNetwork(callbacks=[logger, tracker, learning])\n",
    "ann.train(2,2)     \n",
    "print(tracker)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,region_name,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
